{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Case Study: VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Geometry Group + DeepMind, which revealed the relationship between the depth and performance of the CNN. It achieved 16 to 19 layers depth of CNN structures.<br>\n",
    "* Simple structures: 5 conv-layers, 3 fully-connected layer, 1 softmax output and each layer was divided by max-pooling. \n",
    "* Smaller conv-kernel $3*3$: Shrink the params, and More non-linear mapping.\n",
    "* Smaller max-pooling $2*2$\n",
    "* More channels (64 - 128 - 256 - 512 - 512) and make sure more features would be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGGNet structures as shown (6 networks: A, A-LRN, B, C, D, E), sub-layer from 1 to 4, layer from 11 to 19:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](VGGNets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, VVGNet 16 gives input layer, conv layer, fully-connected layer, and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](VGG16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Input 224*224*3, 2 convolutions by 64 conv-kernels with size 3*3 and ReLU, gives post-convolution szie of 224*224*64\n",
    "    2. Max-pooling with 2*2, gives size 112*112*64\n",
    "    \n",
    "    3. 2 convolutions by 128 conv-kernels with size 3*3 and ReLU, gives 112*112*128\n",
    "    4. Max-pooling with 2*2, gives size 56*56*128\n",
    "    \n",
    "    5. 3 convolutions by 256 conv-kernels with size 3*3 and ReLU, gives 56*56*256\n",
    "    6. Max-pooling with 2*2, gives size 28*28*256\n",
    "    \n",
    "    7. 3 convolutions by 512 conv-kernels with size 3*3 and ReLU, gives 28*28*512\n",
    "    8. Max-pooling with 2*2, gives size 14*14*512\n",
    "    \n",
    "    9. 3 convolutions by 512 conv-kernels with size 3*3 and ReLU, gives 14*14*512\n",
    "    10. Max-pooling with 2*2, gives size 7*7*512\n",
    "    \n",
    "    11. Fully-connected and ReLU with 2 layers of 1*1*4096, and 1 layer of 1*1*1000\n",
    "    12. Softmax to give 1000 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Authors has drawn conclusions by camparing all level of networks:\n",
    "* LRN are not that help\n",
    "* Performance gets better when layer depth growing\n",
    "* $1*1$ convolution is effective, but $3*3$ works better, and larger kernels can be used to learn larger features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet used 4 Geforce GTX titan GPU. This time we are not going to use ImageNet to train, but evaluate the inference (forward) and training (backward) time consume.<br>\n",
    "VGGNet 16 implemented for training time consume evaluation in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# create conv-layer, pass the params into list. \n",
    "# kh: kernel height; kw: kernel width; n_out: Channels\n",
    "# dh: step height; dw: step width; p: params list\n",
    "def conv_builder(input_op, name, kh, kw, n_out, dh, dw, p): \n",
    "    n_in = input_op.get_shape()[-1].value # Channel number\n",
    "\n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\", shape=[kh,kw,n_in,n_out], \n",
    "                                 dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv = tf.nn.conv2d(input_op, kernel, (1,dh,dw,1), padding='SAME')\n",
    "        bias_init_val = tf.constant(0.0, shape=[n_out], dtype=tf.float32)\n",
    "        biases = tf.Variable(bias_init_val, trainable=True, name='b')\n",
    "        z = tf.nn.bias_add(conv, biases)\n",
    "        activation = tf.nn.relu(z, name=scope)\n",
    "        p += [kernel, biases]\n",
    "        return activation\n",
    "    \n",
    "# create fully-connected layer.\n",
    "def fc_builder(input_op, name, n_out, p):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "    \n",
    "    with tf.name_scope(name) as scope:\n",
    "        kernel = tf.get_variable(scope+\"w\", shape=[n_in,n_out], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[n_out], dtype=tf.float32), name='b')\n",
    "        activation = tf.nn.relu_layer(input_op, kernel, biases, name=scope)\n",
    "        p += [kernel, biases]\n",
    "        return activation\n",
    "    \n",
    "# create max-pooling layer.\n",
    "def mpool_builder(input_op, name, kh, kw, dh, dw):\n",
    "    return tf.nn.max_pool(input_op, ksize=[1,kh,kw,1],strides=[1,dh,dw,1],padding='SAME',name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_builder(input_op, keep_prob): # Build VGGNet16 inference\n",
    "    p = []\n",
    "    \n",
    "    conv1_1 = conv_builder(input_op, name='conv1_1', kh=3, kw=3, n_out=64, dh=1, dw=1, p=p)  # 224*224*3 -> 224*224*64\n",
    "    conv1_2 = conv_builder(conv1_1, name='conv1_2', kh=3, kw=3, n_out=64, dh=1, dw=1, p=p)   # ...\n",
    "    pool1 = mpool_builder(conv1_2, name='pool1', kh=2, kw=2, dw=2, dh=2)                      # 224*224*64 -> 112*112*64\n",
    "    \n",
    "    conv2_1 = conv_builder(pool1, name='conv2_1', kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)    # 112*112*64 -> 112*112*128\n",
    "    conv2_2 = conv_builder(conv2_1, name='conv2_2', kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)  # ...\n",
    "    pool2 = mpool_builder(conv2_2, name='pool2', kh=2, kw=2, dw=2, dh=2)                      # 112*112*128 -> 56*56*128\n",
    "    \n",
    "    conv3_1 = conv_builder(pool2, name='conv3_1', kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)    # 56*56*128 -> 56*56*256\n",
    "    conv3_2 = conv_builder(conv3_1, name='conv3_2', kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)  # ...\n",
    "    conv3_3 = conv_builder(conv3_2, name='conv3_3', kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)  # ...\n",
    "    pool3 = mpool_builder(conv3_3, name='pool3', kh=2, kw=2, dw=2, dh=2)                      # 56*56*256 -> 28*28*256\n",
    "    \n",
    "    conv4_1 = conv_builder(pool3, name='conv4_1', kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)    # 28*28*256 -> 28*28*512\n",
    "    conv4_2 = conv_builder(conv4_1, name='conv4_2', kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)  # ...\n",
    "    conv4_3 = conv_builder(conv4_2, name='conv4_3', kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)  # ...\n",
    "    pool4 = mpool_builder(conv4_3, name='pool4', kh=2, kw=2, dw=2, dh=2)                      # 28*28*512 -> 14*14*512\n",
    "    \n",
    "    conv5_1 = conv_builder(pool4, name='conv5_1', kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)    # ...\n",
    "    conv5_2 = conv_builder(conv5_1, name='conv5_2', kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)  # ...\n",
    "    conv5_3 = conv_builder(conv5_2, name='conv5_3', kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)  # ...\n",
    "    pool5 = mpool_builder(conv5_3, name='pool5', kh=2, kw=2, dw=2, dh=2)                      # 14*14*512 -> 7*7*512\n",
    "    \n",
    "    shape = pool5.get_shape()\n",
    "    flattened_shape = shape[1].value * shape[2].value * shape[3].value\n",
    "    reshape1 = tf.reshape(pool5, [-1, flattened_shape], name=\"reshape1\")   # 7*7*512 = 25088 vector\n",
    "    \n",
    "    fc6 = fc_builder(reshape1, name='fc6', n_out=4096, p=p)    # Hidden nodes 4096\n",
    "    fc6_drop = tf.nn.dropout(fc6, keep_prob, name='fc6_drop')  # drop out\n",
    "    \n",
    "    fc7 = fc_builder(fc6_drop, name='fc7', n_out=4096, p=p)\n",
    "    fc7_drop = tf.nn.dropout(fc7, keep_prob, name='fc7_drop')\n",
    "    \n",
    "    fc8 = fc_builder(fc7_drop, name='fc8', n_out=1000, p=p)    # Output nodes 1000 -> Softmax\n",
    "    softmax = tf.nn.softmax(fc8)\n",
    "    predictions = tf.argmax(softmax,1)\n",
    "    \n",
    "    return predictions, softmax, fc8, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_time(session, target, feed, info):\n",
    "    num_steps_burn_in = 10 # warm-up\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    \n",
    "    for i in range(num_batches + num_steps_burn_in):\n",
    "        start_time = time.time()\n",
    "        _ = session.run(target, feed_dict=feed) # feed_dict for drop-out probabilities control\n",
    "        duration = time.time() - start_time\n",
    "        if i >= num_steps_burn_in:\n",
    "            if not i % 10:\n",
    "                print('%s: step %d, duration = %.3f' % (datetime.now(), i - num_steps_burn_in, duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "            \n",
    "        mean = total_duration / num_batches\n",
    "        vari = total_duration_squared / num_batches - mean*mean\n",
    "        stan = math.sqrt(vari)\n",
    "        \n",
    "        print('%s: %s arcoss %d steps, %.3f +/- %.3f sec / batch' % (datetime.now(), info_string, num_batches, mean, stan))\n",
    "\n",
    "\n",
    "def benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size,image_size,image_size,3],dtype=tf.float32,stddev=1e-1)) # not using ImageNet\n",
    "        \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        predictions, softmax, fc8, p = inference_builder(images, keep_prob) # construct VGGNet 16\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        \n",
    "        run_time(sess, predictions, {keep_prob:1.0}, \"Forward\") # Forward run-time\n",
    "        objective = tf.nn.l2_loss(fc8)\n",
    "        grad = tf.gradients(objective, p)\n",
    "        run_time(sess, grad, {keep_prob:0.5}, \"Forward-backward\") # Backward run-time\n",
    "\n",
    "batch_size = 4\n",
    "num_batches = 100\n",
    "benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet reaches 7.3% error rate in ILSVRC 2014. Even though model parameters used in VGGNet are larger than that used in AlexNet, less iterations will reach convergence. This is because the deeper network and smaller kernel could bring hidden normalizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
